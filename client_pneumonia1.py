# -*- coding: utf-8 -*-
"""chest_x_ray_using kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14uGC8-xYbZflYzR2HDEu4yVZmRZGmtb2
"""

!pip install torch torchvision matplotlib scikit-learn

from google.colab import drive
drive.mount('/content/drive')

import os

# List dataset directory
os.listdir('/content/drive/MyDrive/chest_xray')

import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision import datasets, models
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

train_dir = '/content/drive/MyDrive/chest_xray/train'
val_dir   = '/content/drive/MyDrive/chest_xray/val'
test_dir  = '/content/drive/MyDrive/chest_xray/test'

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

train_data = datasets.ImageFolder(train_dir, transform=transform)
val_data   = datasets.ImageFolder(val_dir, transform=transform)
test_data  = datasets.ImageFolder(train_dir, transform=transform)

train_loader = DataLoader(train_data, batch_size=16, shuffle=True)
val_loader   = DataLoader(val_data, batch_size=16)
test_loader  = DataLoader(test_data, batch_size=16)

model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

num_epochs = 5
train_loss_list, val_loss_list, val_acc_list = [], [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    train_loss_list.append(epoch_loss)

    # Validation
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_loss /= len(val_loader.dataset)
    accuracy = 100 * correct / total
    val_loss_list.append(val_loss)
    val_acc_list.append(accuracy)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {accuracy:.2f}%')

plt.figure(figsize=(12,5))

plt.subplot(1, 2, 1)
plt.plot(train_loss_list, label='Train Loss')
plt.plot(val_loss_list, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Train & Validation Loss')

plt.subplot(1, 2, 2)
plt.plot(val_acc_list, label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.title('Validation Accuracy')
plt.show()

model.eval()
y_true, y_pred = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

print(classification_report(y_true, y_pred, target_names=train_data.classes))

torch.save(model.state_dict(), '/content/pneumonia_classifier_resnet18.pth')

import numpy as np
import matplotlib.pyplot as plt

# Display some random images from the dataset
def show_images(loader):
    dataiter = iter(loader)
    # Use next() instead of .next()
    images, labels = next(dataiter)

    # Get a batch of images and labels
    fig = plt.figure(figsize=(12, 8))
    for i in range(6):
        ax = fig.add_subplot(2, 3, i+1)
        # Ensure images are in the correct format for display (H, W, C) and convert to numpy array
        img_to_display = images[i].permute(1, 2, 0).numpy()
        # Handle the normalization applied earlier by denormalizing for display if necessary.
        # If normalization was done with mean 0.5 and std 0.5, uncomment the next two lines:
        # img_to_display = img_to_display * 0.5 + 0.5
        # img_to_display = np.clip(img_to_display, 0, 1) # clip values to be between 0 and 1

        ax.imshow(img_to_display)
        ax.set_title(f'Label: {labels[i].item()}')
        ax.axis('off')
    plt.show()

# Show images from the training set
show_images(train_loader)

plt.figure(figsize=(12,5))

plt.subplot(1, 2, 1)
plt.plot(train_loss_list, label='Train Loss')
plt.plot(val_loss_list, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Train & Validation Loss')

plt.subplot(1, 2, 2)
plt.plot(val_acc_list, label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.title('Validation Accuracy')
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Generate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_data.classes, yticklabels=train_data.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

!pip install torch torchvision matplotlib scikit-learn opencv-python

import torch
import torchvision.transforms as transforms
from torchvision import models
import torch.nn as nn
from PIL import Image
import matplotlib.pyplot as plt
from google.colab import files
import cv2

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load trained model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)
model.load_state_dict(torch.load('/content/pneumonia_classifier_resnet18.pth', map_location=device))  # replace with your path
model = model.to(device)
model.eval()

# Class labels
classes = ['Normal', 'Pneumonia']

uploaded = files.upload()
for fn in uploaded.keys():
    img_path = fn
    print('Uploaded file:', img_path)

# Image preprocessing
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),

    transforms.Normalize([0.5], [0.5])
])

# Load and preprocess image
image = Image.open(img_path).convert('RGB')
input_tensor = transform(image).unsqueeze(0).to(device)

# Make prediction
with torch.no_grad():
    output = model(input_tensor)
    _, predicted = torch.max(output, 1)
    prediction = classes[predicted.item()]

# Show result
print(f"Prediction: {prediction}")

# Display uploaded image
plt.imshow(image, cmap='gray')
plt.title(f'Prediction: {prediction}')
plt.axis('off')
plt.show()

uploaded = files.upload()
for fn in uploaded.keys():
    img_path = fn
    print('Uploaded file:', img_path)

#image preprocessing
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Load and preprocess image
image = Image.open(img_path).convert('RGB')
input_tensor = transform(image).unsqueeze(0).to(device)

# Make prediction
with torch.no_grad():
    output = model(input_tensor)
    _, predicted = torch.max(output, 1)
    prediction = classes[predicted.item()]

# Show result
print(f"Prediction: {prediction}")

# Display uploaded image
plt.imshow(image, cmap='gray')
plt.title(f'Prediction: {prediction}')
plt.axis('off')
plt.show()

